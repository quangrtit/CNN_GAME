{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10348646,"sourceType":"datasetVersion","datasetId":6408208},{"sourceId":216905,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":184940,"modelId":207089}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader, Dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:05:40.909917Z","iopub.execute_input":"2025-01-02T11:05:40.910384Z","iopub.status.idle":"2025-01-02T11:05:40.916254Z","shell.execute_reply.started":"2025-01-02T11:05:40.910348Z","shell.execute_reply":"2025-01-02T11:05:40.915359Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# list tetrominos \nip = [[[0, 0, 0, 0],\n  [0, 0, 0, 0],\n  [1, 1, 1, 1],\n  [0, 0, 0, 0]],\n \n [[0, 0, 1, 0],\n  [0, 0, 1, 0],\n  [0, 0, 1, 0],\n  [0, 0, 1, 0]],\n\n [[0, 0, 0, 0],\n  [1, 1, 1, 1],\n  [0, 0, 0, 0],\n  [0, 0, 0, 0]],\n\n [[0, 1, 0, 0],\n  [0, 1, 0, 0],\n  [0, 1, 0, 0],\n  [0, 1, 0, 0]]]\n\nop = [[[0, 0, 0, 0],\n  [0, 2, 2, 0],\n  [0, 2, 2, 0],\n  [0, 0, 0, 0]],\n\n [[0, 0, 0, 0],\n  [0, 2, 2, 0],\n  [0, 2, 2, 0],\n  [0, 0, 0, 0]],\n\n [[0, 0, 0, 0],\n  [0, 2, 2, 0],\n  [0, 2, 2, 0],\n  [0, 0 ,0 ,0]],\n\n [[0, 0, 0, 0],\n  [0, 2, 2, 0],\n  [0, 2, 2, 0],\n  [0, 0 ,0 ,0]]]\n\njp = [[[0, 0, 0, 0],\n  [3, 0, 0, 0],\n  [3, 3, 3, 0],\n  [0, 0, 0, 0]],\n\n [[0, 0, 0, 0],\n  [0, 3, 3, 0],\n  [0, 3, 0, 0],\n  [0, 3, 0, 0]],\n\n [[0, 0, 0, 0],\n  [0, 0, 0, 0],\n  [3, 3, 3, 0],\n  [0, 0, 3, 0]],\n\n [[0, 0, 0, 0],\n  [0, 3, 0, 0],\n  [0, 3, 0, 0],\n  [3, 3, 0, 0]]]\n\nlp = [[[0, 0, 0, 0],\n  [0, 0, 4, 0],\n  [4, 4, 4, 0],\n  [0, 0, 0, 0]],\n\n [[0, 0, 0, 0],\n  [0, 4, 0, 0],\n  [0, 4, 0, 0],\n  [0, 4, 4, 0]],\n\n [[0, 0, 0, 0],\n  [0, 0, 0, 0],\n  [4, 4, 4, 0],\n  [4, 0, 0, 0]],\n\n [[0, 0, 0, 0],\n  [4, 4, 0, 0],\n  [0, 4, 0, 0],\n  [0, 4, 0, 0]]]\n\nzp = [[[0, 0, 0, 0],\n  [5, 5, 0, 0],\n  [0, 5, 5, 0],\n  [0, 0, 0, 0]],\n\n [[0, 0, 5, 0],\n  [0, 5, 5, 0],\n  [0, 5, 0, 0],\n  [0, 0, 0, 0]],\n\n [[0, 0, 0, 0],\n  [5, 5, 0, 0],\n  [0, 5, 5, 0],\n  [0, 0, 0, 0]],\n\n [[0, 0, 0, 0],\n  [0, 5, 0, 0],\n  [5, 5, 0, 0],\n  [5, 0, 0, 0]]]\n\nsp = [[[0, 0, 0, 0],\n  [0, 6, 6, 0],\n  [6, 6, 0, 0],\n  [0, 0, 0, 0]],\n\n [[0, 0, 0, 0],\n  [0, 6, 0, 0],\n  [0, 6, 6, 0],\n  [0, 0, 6, 0]],\n\n [[0, 0, 0, 0],\n  [0, 6, 6, 0],\n  [6, 6, 0, 0],\n  [0, 0, 0, 0]],\n\n [[6, 0, 0, 0],\n  [6, 6, 0, 0],\n  [0, 6, 0, 0],\n  [0, 0, 0, 0]]]\n\ntp = [[[0, 0, 0, 0],\n  [0, 7, 0, 0],\n  [7, 7, 7, 0],\n  [0, 0, 0, 0]],\n\n [[0, 0, 0, 0],\n  [0, 7, 0, 0],\n  [0, 7, 7, 0],\n  [0, 7, 0, 0]],\n\n [[0, 0, 0, 0],\n  [0, 0, 0, 0],\n  [7, 7, 7, 0],\n  [0, 7, 0, 0]],\n\n [[0, 0, 0, 0],\n  [0, 7, 0, 0],\n  [7, 7, 0, 0],\n  [0, 7, 0, 0]]]\n# get piece from matrix 2d\nlist_block_match = []\nlist_blocks = [ip, op, jp, lp, zp, sp, tp]\nfor i in range(len(list_blocks)):\n  # each block in list block has 4 state rotate\n  list_block_match.append(list_blocks[i][0])\n  list_block_match.append(list_blocks[i][1])\n  list_block_match.append(list_blocks[i][2])\n  list_block_match.append(list_blocks[i][3])\nprint(\"has\", len(list_block_match), \"state match\")\nfor i in range(len(list_block_match)):\n  print(list_block_match[i])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:05:43.826348Z","iopub.execute_input":"2025-01-02T11:05:43.826639Z","iopub.status.idle":"2025-01-02T11:05:43.845953Z","shell.execute_reply.started":"2025-01-02T11:05:43.826617Z","shell.execute_reply":"2025-01-02T11:05:43.845178Z"}},"outputs":[{"name":"stdout","text":"has 28 state match\n[[0, 0, 0, 0], [0, 0, 0, 0], [1, 1, 1, 1], [0, 0, 0, 0]]\n[[0, 0, 1, 0], [0, 0, 1, 0], [0, 0, 1, 0], [0, 0, 1, 0]]\n[[0, 0, 0, 0], [1, 1, 1, 1], [0, 0, 0, 0], [0, 0, 0, 0]]\n[[0, 1, 0, 0], [0, 1, 0, 0], [0, 1, 0, 0], [0, 1, 0, 0]]\n[[0, 0, 0, 0], [0, 2, 2, 0], [0, 2, 2, 0], [0, 0, 0, 0]]\n[[0, 0, 0, 0], [0, 2, 2, 0], [0, 2, 2, 0], [0, 0, 0, 0]]\n[[0, 0, 0, 0], [0, 2, 2, 0], [0, 2, 2, 0], [0, 0, 0, 0]]\n[[0, 0, 0, 0], [0, 2, 2, 0], [0, 2, 2, 0], [0, 0, 0, 0]]\n[[0, 0, 0, 0], [3, 0, 0, 0], [3, 3, 3, 0], [0, 0, 0, 0]]\n[[0, 0, 0, 0], [0, 3, 3, 0], [0, 3, 0, 0], [0, 3, 0, 0]]\n[[0, 0, 0, 0], [0, 0, 0, 0], [3, 3, 3, 0], [0, 0, 3, 0]]\n[[0, 0, 0, 0], [0, 3, 0, 0], [0, 3, 0, 0], [3, 3, 0, 0]]\n[[0, 0, 0, 0], [0, 0, 4, 0], [4, 4, 4, 0], [0, 0, 0, 0]]\n[[0, 0, 0, 0], [0, 4, 0, 0], [0, 4, 0, 0], [0, 4, 4, 0]]\n[[0, 0, 0, 0], [0, 0, 0, 0], [4, 4, 4, 0], [4, 0, 0, 0]]\n[[0, 0, 0, 0], [4, 4, 0, 0], [0, 4, 0, 0], [0, 4, 0, 0]]\n[[0, 0, 0, 0], [5, 5, 0, 0], [0, 5, 5, 0], [0, 0, 0, 0]]\n[[0, 0, 5, 0], [0, 5, 5, 0], [0, 5, 0, 0], [0, 0, 0, 0]]\n[[0, 0, 0, 0], [5, 5, 0, 0], [0, 5, 5, 0], [0, 0, 0, 0]]\n[[0, 0, 0, 0], [0, 5, 0, 0], [5, 5, 0, 0], [5, 0, 0, 0]]\n[[0, 0, 0, 0], [0, 6, 6, 0], [6, 6, 0, 0], [0, 0, 0, 0]]\n[[0, 0, 0, 0], [0, 6, 0, 0], [0, 6, 6, 0], [0, 0, 6, 0]]\n[[0, 0, 0, 0], [0, 6, 6, 0], [6, 6, 0, 0], [0, 0, 0, 0]]\n[[6, 0, 0, 0], [6, 6, 0, 0], [0, 6, 0, 0], [0, 0, 0, 0]]\n[[0, 0, 0, 0], [0, 7, 0, 0], [7, 7, 7, 0], [0, 0, 0, 0]]\n[[0, 0, 0, 0], [0, 7, 0, 0], [0, 7, 7, 0], [0, 7, 0, 0]]\n[[0, 0, 0, 0], [0, 0, 0, 0], [7, 7, 7, 0], [0, 7, 0, 0]]\n[[0, 0, 0, 0], [0, 7, 0, 0], [7, 7, 0, 0], [0, 7, 0, 0]]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# import os\n# import glob\n# import shutil\n# # Đường dẫn tới thư mục working\n# working_dir = '/kaggle/working/'\n\n# # Lấy tất cả các tệp tin và thư mục trong thư mục working\n# files = glob.glob(working_dir + '*')\n\n# # Xóa tất cả các tệp tin và thư mục\n# for file in files:\n#     if os.path.isdir(file):\n#         shutil.rmtree(file)  # Xóa thư mục\n#     else:\n#         os.remove(file)  # Xóa tệp ti","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T05:36:34.378625Z","iopub.execute_input":"2025-01-02T05:36:34.378888Z","iopub.status.idle":"2025-01-02T05:36:34.393872Z","shell.execute_reply.started":"2025-01-02T05:36:34.378868Z","shell.execute_reply":"2025-01-02T05:36:34.393186Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"data_path_load = \"/kaggle/input/data-train/data/\"\nall_dataset = []\ncount_path = 1\nnum_folder = 2\nwhile count_path <= num_folder:\n  dataset_path = data_path_load + \"dataset\" + str(count_path)\n  label_path = data_path_load + \"label\" + str(count_path)\n  dataset = []\n  list_dataset_path = []\n  for i in range(len(list(os.listdir(dataset_path)))):\n    list_dataset_path.append('state_' + str(i) + '.txt')\n  for file_name in list_dataset_path:\n    file_path = os.path.join(dataset_path, file_name)\n    content = np.loadtxt(file_path, dtype=int)\n    dataset.append(content)\n  label = []\n  list_label_path = []\n  for i in range(len(list(os.listdir(label_path)))):\n    list_label_path.append('label_' + str(i) + '.txt')\n  for file_name in list_label_path:\n    file_path = os.path.join(label_path, file_name)\n    with open(file_path, 'r') as file:\n      line = file.readline().strip()\n      label_tuple = tuple(map(int, line.split(',')))\n      label.append((label_tuple[1], label_tuple[2], label_tuple[0]))# px and rotate and py\n  for i in range(len(dataset)):\n    all_dataset.append((dataset[i], label[i]))\n  print(len(all_dataset))\n  count_path += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:05:54.965603Z","iopub.execute_input":"2025-01-02T11:05:54.965915Z","iopub.status.idle":"2025-01-02T11:12:06.314807Z","shell.execute_reply.started":"2025-01-02T11:05:54.965892Z","shell.execute_reply":"2025-01-02T11:12:06.314081Z"}},"outputs":[{"name":"stdout","text":"31175\n52181\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# remove duplicate\ndef compare(obj1, obj2):\n  matrix1 = obj1[0]\n  matrix2 = obj2[0]\n  tp1 = obj1[1]\n  tp2 = obj2[1]\n  if tp1 != tp2:\n    return False\n  if np.array_equal(matrix1, matrix2) == False:\n    return False\n  return True\nall_dataset_new = []\nfor i in range(len(all_dataset)):\n  check = True\n  for j in range(i):\n    if compare(all_dataset[i], all_dataset[j]) == True:\n      # print(all_dataset[i][0], all_dataset[j][0])\n      # print(all_dataset[i][1], all_dataset[j][1])\n      check = False\n      break\n  if check:\n    all_dataset_new.append(all_dataset[i])\nprint(\"len before: \", len(all_dataset_new))\nprint(\"len after: \", len(all_dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:17:34.621208Z","iopub.execute_input":"2025-01-02T11:17:34.621559Z","iopub.status.idle":"2025-01-02T11:25:10.783487Z","shell.execute_reply.started":"2025-01-02T11:17:34.621525Z","shell.execute_reply":"2025-01-02T11:25:10.782709Z"}},"outputs":[{"name":"stdout","text":"len before:  48182\nlen after:  52181\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# save dataset\ndata_directory = \"/kaggle/working/data_train/dataset\"\nlabels_directory = \"/kaggle/working/data_train/label\"\nos.makedirs(data_directory, exist_ok=True)\nos.makedirs(labels_directory, exist_ok=True)\n\n# save data\nfor i in range(len(all_dataset_new)):\n    # save input by file .txt\n    matrix_path = os.path.join(data_directory, f'state_{i}.txt')\n    np.savetxt(matrix_path, all_dataset_new[i][0], fmt='%d')\n    # save label in file .txt\n    label_path = os.path.join(labels_directory, f'label_{i}.txt')\n    with open(label_path, 'w') as f:\n        f.write(f\"{all_dataset_new[i][1][0]}, {all_dataset_new[i][1][1]}, {all_dataset_new[i][1][2]}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:27:33.816911Z","iopub.execute_input":"2025-01-02T11:27:33.817264Z","iopub.status.idle":"2025-01-02T11:27:51.728670Z","shell.execute_reply.started":"2025-01-02T11:27:33.817236Z","shell.execute_reply":"2025-01-02T11:27:51.727967Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# check again =)))\nfolder_path = \"/kaggle/working/data_train/dataset\"\n\n# Đếm số lượng file trong thư mục và các thư mục con\nfile_count = sum(len(files) for _, _, files in os.walk(folder_path))\n\nprint(f\"Số lượng file trong thư mục: {file_count}\")\nl_filename = []\nfor file_name in os.listdir(folder_path):\n  l_filename.append(file_name)\nl_filename = set(l_filename)\nprint(len(l_filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:27:51.729907Z","iopub.execute_input":"2025-01-02T11:27:51.730216Z","iopub.status.idle":"2025-01-02T11:27:51.803692Z","shell.execute_reply.started":"2025-01-02T11:27:51.730186Z","shell.execute_reply":"2025-01-02T11:27:51.803104Z"}},"outputs":[{"name":"stdout","text":"Số lượng file trong thư mục: 48182\n48182\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"dict_action = {}\ncnt = 0\nfor i in range(0, 11):\n    for j in range(0, 4):\n        dict_action[i * 10 + j] = cnt \n        cnt += 1\nprint(dict_action)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:36:03.801639Z","iopub.execute_input":"2025-01-02T11:36:03.801956Z","iopub.status.idle":"2025-01-02T11:36:03.807123Z","shell.execute_reply.started":"2025-01-02T11:36:03.801926Z","shell.execute_reply":"2025-01-02T11:36:03.806211Z"}},"outputs":[{"name":"stdout","text":"{0: 0, 1: 1, 2: 2, 3: 3, 10: 4, 11: 5, 12: 6, 13: 7, 20: 8, 21: 9, 22: 10, 23: 11, 30: 12, 31: 13, 32: 14, 33: 15, 40: 16, 41: 17, 42: 18, 43: 19, 50: 20, 51: 21, 52: 22, 53: 23, 60: 24, 61: 25, 62: 26, 63: 27, 70: 28, 71: 29, 72: 30, 73: 31, 80: 32, 81: 33, 82: 34, 83: 35, 90: 36, 91: 37, 92: 38, 93: 39, 100: 40, 101: 41, 102: 42, 103: 43}\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# load data train \n# Đường dẫn tới thư mục dữ liệu\ndataset_path = \"/kaggle/working/data_train/dataset\"\nlabel_path = \"/kaggle/working/data_train/label\"\n# data train \ndataset = []\nlabels = []\nlocations = []\n# data \nlist_dataset_path = []\nfor i in range(len(list(os.listdir(dataset_path)))):\n    list_dataset_path.append('state_' + str(i) + '.txt')\nfor file_name in list_dataset_path:\n    file_path = os.path.join(dataset_path, file_name)\n    content = np.loadtxt(file_path, dtype=int)\n    dataset.append(content)\n# label \nlist_label_path = []\nfor i in range(len(list(os.listdir(label_path)))):\n    list_label_path.append('label_' + str(i) + '.txt')\nfor file_name in list_label_path:\n    file_path = os.path.join(label_path, file_name)\n    with open(file_path, 'r') as file:\n        line = file.readline().strip()\n        label_tuple = tuple(map(int, line.split(',')))\n        locations.append((label_tuple[0] - 2, label_tuple[1], label_tuple[2]))\n        # note add 2 for px\n        labels.append(dict_action[(label_tuple[0]) * 10 + (label_tuple[1] % 4)])# px(-2, 8) and rotate(0, 27) => px(-2 + 2, 8 + 2) and rotate(x % 4) => (0, 43)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:36:06.647319Z","iopub.execute_input":"2025-01-02T11:36:06.647620Z","iopub.status.idle":"2025-01-02T11:36:13.478457Z","shell.execute_reply.started":"2025-01-02T11:36:06.647597Z","shell.execute_reply":"2025-01-02T11:36:13.477534Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# preprocess data\ndef fill_holes(binary_matrix):\n    binary_matrix = binary_matrix.T\n    new_binary_matrix = np.copy(binary_matrix)\n    for i in range(5, len(binary_matrix) - 5):\n        occupied = 0  # Set the 'Occupied' flag to 0 for each new column\n        for j in range(0, len(binary_matrix[0])):  # Scan from top to bottom\n            if int(binary_matrix[i][j]) > 0:\n                occupied = 1  # If a block is found, set the 'Occupied' flag to 1\n            if int(binary_matrix[i][j]) == 0 and occupied == 1: \n                new_binary_matrix[i][j] = 1\n    return new_binary_matrix.T \nfor i in range(len(dataset)):\n    dataset[i] = np.copy(fill_holes(dataset[i]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:36:18.625072Z","iopub.execute_input":"2025-01-02T11:36:18.625361Z","iopub.status.idle":"2025-01-02T11:36:24.635960Z","shell.execute_reply.started":"2025-01-02T11:36:18.625338Z","shell.execute_reply":"2025-01-02T11:36:24.635168Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Tập hợp để lưu các cặp (data, label) duy nhất\nunique_data_label_pairs = set()\n\n# Danh sách mới để lưu trữ dữ liệu và nhãn không trùng lặp\nunique_dataset = []\nunique_labels = []\nunique_locations = []\n\nfor data, label, location in zip(dataset, labels, locations):\n    # Chuyển mảng NumPy sang tuple để có thể sử dụng trong set\n    data_tuple = tuple(map(tuple, data))  # Chuyển ma trận 2D thành tuple các tuple\n    pair = (data_tuple, label)\n    \n    # Nếu cặp này chưa tồn tại trong set, thêm vào\n    if pair not in unique_data_label_pairs:\n        unique_data_label_pairs.add(pair)\n        unique_dataset.append(data)\n        unique_labels.append(label)\n        unique_locations.append(location)\n\n# Ghi đè lại dataset, labels và locations\ndataset = unique_dataset\nlabels = unique_labels\nlocations = unique_locations\n\nprint(f\"Số lượng dữ liệu ban đầu: {len(unique_dataset) + len(unique_data_label_pairs)}\")\nprint(f\"Số lượng dữ liệu sau khi loại bỏ trùng lặp: {len(dataset)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:36:27.870834Z","iopub.execute_input":"2025-01-02T11:36:27.871176Z","iopub.status.idle":"2025-01-02T11:36:31.032202Z","shell.execute_reply.started":"2025-01-02T11:36:27.871149Z","shell.execute_reply":"2025-01-02T11:36:31.031445Z"}},"outputs":[{"name":"stdout","text":"Số lượng dữ liệu ban đầu: 96364\nSố lượng dữ liệu sau khi loại bỏ trùng lặp: 48182\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"new_dataset = []\nnew_labels = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:36:36.444307Z","iopub.execute_input":"2025-01-02T11:36:36.444618Z","iopub.status.idle":"2025-01-02T11:36:36.448977Z","shell.execute_reply.started":"2025-01-02T11:36:36.444593Z","shell.execute_reply":"2025-01-02T11:36:36.447897Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# add data by remove row \ndef detect_piece(binary_matrix, locations): \n    # get y_min, y_max \n    px = locations[0]\n    id_block = locations[1]\n    py = locations[2]\n    py_max = py - 100\n    py_min = py + 100\n    block_now = list_block_match[id_block] \n    for i in range(len(block_now)):\n        for j in range(len(block_now[0])):\n            if py + i >= 20:\n                continue\n            if binary_matrix[py + i][px + 5 + j] != 0: \n                py_min = min(py_min, py + i) \n                py_max = max(py_max, py + i) \n    if py_min == py + 100 or py_max == py - 100: \n        py_min = -100 \n        py_max = 100\n    return py_min, py_max\ndef remove_row(binary_matrix, locations):\n    py_min, py_max = detect_piece(binary_matrix, locations)\n    list_binary_matrix = []\n    list_binary_matrix.append(binary_matrix)\n    # remove row bottom \n    binary_matrix_rm_bottom = np.copy(binary_matrix)\n    for py in range(py_max + 1, len(binary_matrix_rm_bottom)):\n        for i in range(len(binary_matrix_rm_bottom) - 1, 0, -1):\n            binary_matrix_rm_bottom[i, 5:(len(binary_matrix_rm_bottom) - 5)] = binary_matrix_rm_bottom[i - 1, 5:(len(binary_matrix_rm_bottom) - 5)]\n        binary_matrix_rm_bottom[0, 5:(len(binary_matrix_rm_bottom) - 5)] = np.zeros(10)\n        list_binary_matrix.append(binary_matrix_rm_bottom)\n    # remove row top\n    binary_matrix_rm_top = np.copy(binary_matrix)\n    # print(binary_matrix_rm_top)\n    if py_min >= 20: \n        print(locations)\n        print(py_min)\n        list_block_match[locations[1]] \n        print(binary_matrix)\n    for i in range(0, py_min):   \n        if not np.all(binary_matrix_rm_top[i, 5:(len(binary_matrix_rm_top) - 5)] == 0):\n            binary_matrix_rm_top[i, 5:(len(binary_matrix_rm_top) - 5)] = np.zeros(10) \n            list_binary_matrix.append(binary_matrix_rm_top) \n\n    return list_binary_matrix\nfor i in range(0, len(dataset)):\n    binary_matrix = dataset[i] \n    lb = labels[i]\n    list_new_data = remove_row(binary_matrix, locations[i])\n    for val in list_new_data: \n        new_dataset.append(val) \n        new_labels.append(lb)\nprint(\"len before: \", len(dataset))\nprint(\"len after: \", len(new_dataset))\nfrom copy import deepcopy\ndataset = deepcopy(new_dataset)\nlabels = deepcopy(new_labels)\nprint(\"len after copy: \", len(dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:36:40.566144Z","iopub.execute_input":"2025-01-02T11:36:40.566502Z","iopub.status.idle":"2025-01-02T11:36:46.196112Z","shell.execute_reply.started":"2025-01-02T11:36:40.566469Z","shell.execute_reply":"2025-01-02T11:36:46.195323Z"}},"outputs":[{"name":"stdout","text":"len before:  48182\nlen after:  167230\nlen after copy:  167230\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# Augmenting Data\ndef interpolate_data(binary_matrix, insert_row):\n    cnt_insert = insert_row \n    new_binary_matrix = np.copy(binary_matrix)\n    for i in range(len(new_binary_matrix) - 1, -1, -1):\n        check_insert = False \n        if insert_row > 0:\n            check_insert = True \n            insert_row -= 1\n        for j in range(5, len(new_binary_matrix[0]) - 5):\n            if check_insert: \n                new_binary_matrix[i][j] = 1       \n            else: \n                new_binary_matrix[i][j] = binary_matrix[i + cnt_insert][j]\n    return new_binary_matrix \ndef get_insert_row(binary_matrix):\n    insert_row = 30 \n    for j in range(5, len(binary_matrix[0]) - 5):\n        ii = 0 \n        while ii < len(binary_matrix) and binary_matrix[ii][j] == 0:\n            ii += 1 \n        insert_row = min(insert_row, ii)         \n    return max(0, insert_row - 3)\n\nfor i in range(len(dataset)):\n    binary_matrix = dataset[i]\n    max_insert_row = get_insert_row(binary_matrix)\n    for ins in range(0, max_insert_row + 1):\n        new_dataset.append(interpolate_data(binary_matrix, ins))\n        new_labels.append(labels[i])\n\nprint(\"len before: \", len(dataset))\nprint(\"len after: \", len(new_dataset)) # new_dataset and new_labels\n     ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:36:58.196633Z","iopub.execute_input":"2025-01-02T11:36:58.196912Z","iopub.status.idle":"2025-01-02T11:40:36.716224Z","shell.execute_reply.started":"2025-01-02T11:36:58.196892Z","shell.execute_reply":"2025-01-02T11:40:36.715306Z"}},"outputs":[{"name":"stdout","text":"len before:  167230\nlen after:  2660639\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# last_dataset = []\n# last_labels = []\n# # remove duplicate\n# def compare(matrix1, matrix2, tp1, tp2):\n#   if tp1 != tp2:\n#     return False\n#   if np.array_equal(matrix1, matrix2) == False:\n#     return False\n#   return True\n# for i in range(len(new_dataset)):\n#   check = True\n#   for j in range(i):\n#     if compare(new_dataset[i], new_dataset[j], new_labels[i], new_labels[j]) == True:\n#       check = False\n#       break\n#   if check:\n#     last_dataset.append(new_dataset[i])\n#     last_labels.append(new_labels[i])\n# print(\"len before: \", len(new_dataset))\n# print(\"len after: \", len(last_dataset), len(last_labels))\nlast_dataset = []\nlast_labels = []\nunique_set = set()\n\nfor i in range(len(new_dataset)):\n    # Chuyển ma trận thành tuple để có thể lưu trữ trong set\n    matrix_tuple = tuple(new_dataset[i].flatten())  # Chuyển ma trận thành 1D\n    label = new_labels[i]\n    unique_key = (matrix_tuple, label)\n    \n    if unique_key not in unique_set:\n        unique_set.add(unique_key)\n        last_dataset.append(new_dataset[i])\n        last_labels.append(label)\n\nprint(\"len before: \", len(new_dataset))\nprint(\"len after: \", len(last_dataset), len(last_labels))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:40:43.367340Z","iopub.execute_input":"2025-01-02T11:40:43.367650Z","iopub.status.idle":"2025-01-02T11:42:13.900253Z","shell.execute_reply.started":"2025-01-02T11:40:43.367621Z","shell.execute_reply":"2025-01-02T11:42:13.899254Z"}},"outputs":[{"name":"stdout","text":"len before:  2660639\nlen after:  989699 989699\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"del unique_set","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:42:20.649318Z","iopub.execute_input":"2025-01-02T11:42:20.649604Z","iopub.status.idle":"2025-01-02T11:42:27.103879Z","shell.execute_reply.started":"2025-01-02T11:42:20.649581Z","shell.execute_reply":"2025-01-02T11:42:27.103068Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"dataset = np.array(last_dataset)\nlabels = np.array(last_labels)\n# dataset = np.array(dataset)\n# labels = np.array(labels)\nprint(len(dataset), labels)\n# Chia dữ liệu thành tập train và test\nX_train, X_test, y_train, y_test = train_test_split(dataset, labels, test_size=0.01, random_state=42)\n\n# Chuyển đổi dữ liệu thành tensor PyTorch\nX_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)  # Thêm chiều kênh: (batch_size, 1, 20, 20)\nX_test = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)\n\ny_train = torch.tensor(y_train, dtype=torch.long)  # Nhãn phải là dtype long cho classification\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# Tạo DataLoader cho train và test\nclass TetrisDataset(Dataset):\n    def __init__(self, data, labels):\n        self.data = data\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        return self.data[idx], self.labels[idx]\n\ntrain_dataset = TetrisDataset(X_train, y_train)\ntest_dataset = TetrisDataset(X_test, y_test)\n\ntrain_loader = DataLoader(train_dataset, batch_size=1024 * 4, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:42:35.950423Z","iopub.execute_input":"2025-01-02T11:42:35.950743Z","iopub.status.idle":"2025-01-02T11:42:39.607895Z","shell.execute_reply.started":"2025-01-02T11:42:35.950714Z","shell.execute_reply":"2025-01-02T11:42:39.606990Z"}},"outputs":[{"name":"stdout","text":"989699 [38 38 38 ... 33 33 33]\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"class TetrisCNN(nn.Module):\n    def __init__(self):\n        super(TetrisCNN, self).__init__()\n\n        # Convolutional layers\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, stride=5)  # Output: (32, 4, 4)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1)  # Output: (64, 2, 2)\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=2, stride=1)  # Output: (128, 1, 1)\n\n        # Flatten layer\n        self.flatten = nn.Flatten()\n\n        # Fully connected layers\n        self.fc1 = nn.Linear(128 * 1 * 1, 512)  # Adjusted input size to match output of conv3\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 44)  # Output size is 44\n\n    def forward(self, x):\n        # Convolutional layers with ReLU activation\n        x = F.relu(self.conv1(x))  # Output size: (batch_size, 32, 4, 4)\n        x = F.relu(self.conv2(x))  # Output size: (batch_size, 64, 2, 2)\n        x = F.relu(self.conv3(x))  # Output size: (batch_size, 128, 1, 1)\n\n        # Flatten the output\n        x = self.flatten(x)  # Output size: (batch_size, 128)\n\n        # Fully connected layers with ReLU\n        x = F.relu(self.fc1(x))  # Output size: (batch_size, 512)\n        x = F.relu(self.fc2(x))  # Output size: (batch_size, 256)\n        x = self.fc3(x)  # Output layer, no ReLU, output size: (batch_size, 44)\n\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:42:41.400803Z","iopub.execute_input":"2025-01-02T11:42:41.401166Z","iopub.status.idle":"2025-01-02T11:42:41.408047Z","shell.execute_reply.started":"2025-01-02T11:42:41.401134Z","shell.execute_reply":"2025-01-02T11:42:41.406984Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\n# Khởi tạo mạng CNN\nmodel = TetrisCNN().to(device)  # Chuyển mô hình vào GPU nếu có\nmodel_path = '/kaggle/input/cnn1/pytorch/default/1/model_tetris_cnn7.pth'\nmodel.load_state_dict(torch.load(model_path))\n\n# Định nghĩa Loss function và Optimizer\ncriterion = nn.CrossEntropyLoss()  # Hàm mất mát cho phân loại\noptimizer = optim.Adam(model.parameters(), lr=0.0005 * 2)  # Optimizer Adam\n\n# Huấn luyện mạng CNN\nepochs = 100\nfor epoch in range(epochs):\n    model.train()  # Đặt mạng ở chế độ huấn luyện\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    for images, labels in train_loader:\n        # Chuyển dữ liệu vào GPU\n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()  # Làm mới gradient\n        # Forward pass\n        outputs = model(images)\n        # print(outputs)\n        # print(labels)\n        # Tính loss\n        loss = criterion(outputs, labels)\n        \n        # Backward pass và cập nhật weights\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()  # Cộng dồn loss\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n    \n    print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%')\n\n# Kiểm tra độ chính xác trên tập kiểm tra\nmodel.eval()  # Đặt mạng ở chế độ kiểm tra\ncorrect = 0\ntotal = 0\nwith torch.no_grad():  # Tắt tính toán gradient trong quá trình kiểm tra\n    for images, labels in test_loader:\n        # Chuyển dữ liệu vào GPU\n        images, labels = images.to(device), labels.to(device)\n        \n        outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f'Test Accuracy: {100 * correct / total:.2f}%')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T11:42:46.409905Z","iopub.execute_input":"2025-01-02T11:42:46.410265Z","iopub.status.idle":"2025-01-02T12:13:06.439517Z","shell.execute_reply.started":"2025-01-02T11:42:46.410232Z","shell.execute_reply":"2025-01-02T12:13:06.438776Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-30-d85ad634216d>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(model_path))\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100, Loss: 0.2060, Accuracy: 93.03%\nEpoch 2/100, Loss: 0.1488, Accuracy: 94.01%\nEpoch 3/100, Loss: 0.1657, Accuracy: 93.46%\nEpoch 4/100, Loss: 0.1641, Accuracy: 93.50%\nEpoch 5/100, Loss: 0.1621, Accuracy: 93.57%\nEpoch 6/100, Loss: 0.1737, Accuracy: 93.18%\nEpoch 7/100, Loss: 0.1650, Accuracy: 93.47%\nEpoch 8/100, Loss: 0.1641, Accuracy: 93.50%\nEpoch 9/100, Loss: 0.1667, Accuracy: 93.41%\nEpoch 10/100, Loss: 0.1643, Accuracy: 93.49%\nEpoch 11/100, Loss: 0.1660, Accuracy: 93.43%\nEpoch 12/100, Loss: 0.1630, Accuracy: 93.54%\nEpoch 13/100, Loss: 0.1687, Accuracy: 93.37%\nEpoch 14/100, Loss: 0.1686, Accuracy: 93.35%\nEpoch 15/100, Loss: 0.1646, Accuracy: 93.49%\nEpoch 16/100, Loss: 0.1671, Accuracy: 93.41%\nEpoch 17/100, Loss: 0.1612, Accuracy: 93.63%\nEpoch 18/100, Loss: 0.1629, Accuracy: 93.56%\nEpoch 19/100, Loss: 0.1701, Accuracy: 93.33%\nEpoch 20/100, Loss: 0.1663, Accuracy: 93.45%\nEpoch 21/100, Loss: 0.1647, Accuracy: 93.53%\nEpoch 22/100, Loss: 0.1615, Accuracy: 93.62%\nEpoch 23/100, Loss: 0.1623, Accuracy: 93.59%\nEpoch 24/100, Loss: 0.1639, Accuracy: 93.55%\nEpoch 25/100, Loss: 0.1608, Accuracy: 93.63%\nEpoch 26/100, Loss: 0.1686, Accuracy: 93.36%\nEpoch 27/100, Loss: 0.1596, Accuracy: 93.66%\nEpoch 28/100, Loss: 0.1596, Accuracy: 93.66%\nEpoch 29/100, Loss: 0.1663, Accuracy: 93.43%\nEpoch 30/100, Loss: 0.1615, Accuracy: 93.62%\nEpoch 31/100, Loss: 0.1655, Accuracy: 93.49%\nEpoch 32/100, Loss: 0.1638, Accuracy: 93.53%\nEpoch 33/100, Loss: 0.1601, Accuracy: 93.69%\nEpoch 34/100, Loss: 0.1618, Accuracy: 93.61%\nEpoch 35/100, Loss: 0.1594, Accuracy: 93.71%\nEpoch 36/100, Loss: 0.1634, Accuracy: 93.59%\nEpoch 37/100, Loss: 0.1602, Accuracy: 93.69%\nEpoch 38/100, Loss: 0.1575, Accuracy: 93.76%\nEpoch 39/100, Loss: 0.1575, Accuracy: 93.79%\nEpoch 40/100, Loss: 0.1645, Accuracy: 93.56%\nEpoch 41/100, Loss: 0.1575, Accuracy: 93.76%\nEpoch 42/100, Loss: 0.1604, Accuracy: 93.68%\nEpoch 43/100, Loss: 0.1644, Accuracy: 93.53%\nEpoch 44/100, Loss: 0.1584, Accuracy: 93.74%\nEpoch 45/100, Loss: 0.1574, Accuracy: 93.76%\nEpoch 46/100, Loss: 0.1603, Accuracy: 93.67%\nEpoch 47/100, Loss: 0.1604, Accuracy: 93.68%\nEpoch 48/100, Loss: 0.1591, Accuracy: 93.71%\nEpoch 49/100, Loss: 0.1585, Accuracy: 93.74%\nEpoch 50/100, Loss: 0.1508, Accuracy: 93.98%\nEpoch 51/100, Loss: 0.1555, Accuracy: 93.84%\nEpoch 52/100, Loss: 0.1631, Accuracy: 93.61%\nEpoch 53/100, Loss: 0.1566, Accuracy: 93.81%\nEpoch 54/100, Loss: 0.1589, Accuracy: 93.75%\nEpoch 55/100, Loss: 0.1535, Accuracy: 93.90%\nEpoch 56/100, Loss: 0.1554, Accuracy: 93.84%\nEpoch 57/100, Loss: 0.1570, Accuracy: 93.78%\nEpoch 58/100, Loss: 0.1581, Accuracy: 93.75%\nEpoch 59/100, Loss: 0.1589, Accuracy: 93.73%\nEpoch 60/100, Loss: 0.1535, Accuracy: 93.90%\nEpoch 61/100, Loss: 0.1512, Accuracy: 93.99%\nEpoch 62/100, Loss: 0.1614, Accuracy: 93.67%\nEpoch 63/100, Loss: 0.1537, Accuracy: 93.89%\nEpoch 64/100, Loss: 0.1603, Accuracy: 93.71%\nEpoch 65/100, Loss: 0.1571, Accuracy: 93.80%\nEpoch 66/100, Loss: 0.1550, Accuracy: 93.86%\nEpoch 67/100, Loss: 0.1528, Accuracy: 93.93%\nEpoch 68/100, Loss: 0.1525, Accuracy: 93.96%\nEpoch 69/100, Loss: 0.1588, Accuracy: 93.77%\nEpoch 70/100, Loss: 0.1561, Accuracy: 93.84%\nEpoch 71/100, Loss: 0.1540, Accuracy: 93.91%\nEpoch 72/100, Loss: 0.1621, Accuracy: 93.63%\nEpoch 73/100, Loss: 0.1504, Accuracy: 94.02%\nEpoch 74/100, Loss: 0.1507, Accuracy: 94.03%\nEpoch 75/100, Loss: 0.1532, Accuracy: 93.92%\nEpoch 76/100, Loss: 0.1535, Accuracy: 93.93%\nEpoch 77/100, Loss: 0.1474, Accuracy: 94.12%\nEpoch 78/100, Loss: 0.1597, Accuracy: 93.70%\nEpoch 79/100, Loss: 0.1451, Accuracy: 94.19%\nEpoch 80/100, Loss: 0.1509, Accuracy: 94.01%\nEpoch 81/100, Loss: 0.1580, Accuracy: 93.79%\nEpoch 82/100, Loss: 0.1526, Accuracy: 93.95%\nEpoch 83/100, Loss: 0.1536, Accuracy: 93.91%\nEpoch 84/100, Loss: 0.1544, Accuracy: 93.92%\nEpoch 85/100, Loss: 0.1508, Accuracy: 94.04%\nEpoch 86/100, Loss: 0.1527, Accuracy: 93.93%\nEpoch 87/100, Loss: 0.1482, Accuracy: 94.09%\nEpoch 88/100, Loss: 0.1533, Accuracy: 93.92%\nEpoch 89/100, Loss: 0.1556, Accuracy: 93.86%\nEpoch 90/100, Loss: 0.1527, Accuracy: 93.96%\nEpoch 91/100, Loss: 0.1577, Accuracy: 93.80%\nEpoch 92/100, Loss: 0.1458, Accuracy: 94.19%\nEpoch 93/100, Loss: 0.1509, Accuracy: 94.01%\nEpoch 94/100, Loss: 0.1493, Accuracy: 94.08%\nEpoch 95/100, Loss: 0.1583, Accuracy: 93.79%\nEpoch 96/100, Loss: 0.1481, Accuracy: 94.11%\nEpoch 97/100, Loss: 0.1474, Accuracy: 94.13%\nEpoch 98/100, Loss: 0.1515, Accuracy: 93.99%\nEpoch 99/100, Loss: 0.1532, Accuracy: 93.97%\nEpoch 100/100, Loss: 0.1531, Accuracy: 93.94%\nTest Accuracy: 92.80%\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"for epoch in range(200):\n    model.train()  # Đặt mạng ở chế độ huấn luyện\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    for images, labels in train_loader:\n        # Chuyển dữ liệu vào GPU\n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()  # Làm mới gradient\n        # Forward pass\n        outputs = model(images)\n        # print(outputs)\n        # print(labels)\n        # Tính loss\n        loss = criterion(outputs, labels)\n        \n        # Backward pass và cập nhật weights\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()  # Cộng dồn loss\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n    \n    print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%')\n\n# Kiểm tra độ chính xác trên tập kiểm tra\nmodel.eval()  # Đặt mạng ở chế độ kiểm tra\ncorrect = 0\ntotal = 0\nwith torch.no_grad():  # Tắt tính toán gradient trong quá trình kiểm tra\n    for images, labels in test_loader:\n        # Chuyển dữ liệu vào GPU\n        images, labels = images.to(device), labels.to(device)\n        \n        outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f'Test Accuracy: {100 * correct / total:.2f}%')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T14:29:31.128455Z","iopub.execute_input":"2025-01-02T14:29:31.128784Z","iopub.status.idle":"2025-01-02T15:29:28.509037Z","shell.execute_reply.started":"2025-01-02T14:29:31.128756Z","shell.execute_reply":"2025-01-02T15:29:28.508234Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100, Loss: 0.1258, Accuracy: 94.80%\nEpoch 2/100, Loss: 0.1232, Accuracy: 94.87%\nEpoch 3/100, Loss: 0.1254, Accuracy: 94.83%\nEpoch 4/100, Loss: 0.1235, Accuracy: 94.86%\nEpoch 5/100, Loss: 0.1236, Accuracy: 94.86%\nEpoch 6/100, Loss: 0.1217, Accuracy: 94.93%\nEpoch 7/100, Loss: 0.1229, Accuracy: 94.91%\nEpoch 8/100, Loss: 0.1241, Accuracy: 94.84%\nEpoch 9/100, Loss: 0.1270, Accuracy: 94.78%\nEpoch 10/100, Loss: 0.1216, Accuracy: 94.89%\nEpoch 11/100, Loss: 0.1238, Accuracy: 94.87%\nEpoch 12/100, Loss: 0.1229, Accuracy: 94.88%\nEpoch 13/100, Loss: 0.1231, Accuracy: 94.88%\nEpoch 14/100, Loss: 0.1239, Accuracy: 94.85%\nEpoch 15/100, Loss: 0.1236, Accuracy: 94.89%\nEpoch 16/100, Loss: 0.1235, Accuracy: 94.88%\nEpoch 17/100, Loss: 0.1239, Accuracy: 94.86%\nEpoch 18/100, Loss: 0.1233, Accuracy: 94.91%\nEpoch 19/100, Loss: 0.1234, Accuracy: 94.88%\nEpoch 20/100, Loss: 0.1261, Accuracy: 94.80%\nEpoch 21/100, Loss: 0.1230, Accuracy: 94.88%\nEpoch 22/100, Loss: 0.1231, Accuracy: 94.89%\nEpoch 23/100, Loss: 0.1212, Accuracy: 94.92%\nEpoch 24/100, Loss: 0.1223, Accuracy: 94.91%\nEpoch 25/100, Loss: 0.1235, Accuracy: 94.85%\nEpoch 26/100, Loss: 0.1244, Accuracy: 94.85%\nEpoch 27/100, Loss: 0.1230, Accuracy: 94.88%\nEpoch 28/100, Loss: 0.1228, Accuracy: 94.88%\nEpoch 29/100, Loss: 0.1242, Accuracy: 94.87%\nEpoch 30/100, Loss: 0.1252, Accuracy: 94.82%\nEpoch 31/100, Loss: 0.1218, Accuracy: 94.91%\nEpoch 32/100, Loss: 0.1232, Accuracy: 94.87%\nEpoch 33/100, Loss: 0.1223, Accuracy: 94.88%\nEpoch 34/100, Loss: 0.1223, Accuracy: 94.89%\nEpoch 35/100, Loss: 0.1239, Accuracy: 94.85%\nEpoch 36/100, Loss: 0.1206, Accuracy: 94.95%\nEpoch 37/100, Loss: 0.1226, Accuracy: 94.91%\nEpoch 38/100, Loss: 0.1234, Accuracy: 94.86%\nEpoch 39/100, Loss: 0.1263, Accuracy: 94.79%\nEpoch 40/100, Loss: 0.1230, Accuracy: 94.86%\nEpoch 41/100, Loss: 0.1224, Accuracy: 94.92%\nEpoch 42/100, Loss: 0.1225, Accuracy: 94.91%\nEpoch 43/100, Loss: 0.1214, Accuracy: 94.96%\nEpoch 44/100, Loss: 0.1218, Accuracy: 94.93%\nEpoch 45/100, Loss: 0.1233, Accuracy: 94.86%\nEpoch 46/100, Loss: 0.1223, Accuracy: 94.90%\nEpoch 47/100, Loss: 0.1245, Accuracy: 94.85%\nEpoch 48/100, Loss: 0.1231, Accuracy: 94.86%\nEpoch 49/100, Loss: 0.1226, Accuracy: 94.89%\nEpoch 50/100, Loss: 0.1196, Accuracy: 94.96%\nEpoch 51/100, Loss: 0.1227, Accuracy: 94.90%\nEpoch 52/100, Loss: 0.1229, Accuracy: 94.87%\nEpoch 53/100, Loss: 0.1224, Accuracy: 94.90%\nEpoch 54/100, Loss: 0.1226, Accuracy: 94.88%\nEpoch 55/100, Loss: 0.1210, Accuracy: 94.92%\nEpoch 56/100, Loss: 0.1221, Accuracy: 94.89%\nEpoch 57/100, Loss: 0.1224, Accuracy: 94.88%\nEpoch 58/100, Loss: 0.1226, Accuracy: 94.88%\nEpoch 59/100, Loss: 0.1236, Accuracy: 94.85%\nEpoch 60/100, Loss: 0.1240, Accuracy: 94.84%\nEpoch 61/100, Loss: 0.1201, Accuracy: 94.94%\nEpoch 62/100, Loss: 0.1210, Accuracy: 94.95%\nEpoch 63/100, Loss: 0.1199, Accuracy: 94.98%\nEpoch 64/100, Loss: 0.1212, Accuracy: 94.93%\nEpoch 65/100, Loss: 0.1222, Accuracy: 94.91%\nEpoch 66/100, Loss: 0.1219, Accuracy: 94.90%\nEpoch 67/100, Loss: 0.1217, Accuracy: 94.93%\nEpoch 68/100, Loss: 0.1210, Accuracy: 94.95%\nEpoch 69/100, Loss: 0.1223, Accuracy: 94.92%\nEpoch 70/100, Loss: 0.1229, Accuracy: 94.89%\nEpoch 71/100, Loss: 0.1215, Accuracy: 94.93%\nEpoch 72/100, Loss: 0.1209, Accuracy: 94.94%\nEpoch 73/100, Loss: 0.1208, Accuracy: 94.94%\nEpoch 74/100, Loss: 0.1199, Accuracy: 94.96%\nEpoch 75/100, Loss: 0.1202, Accuracy: 94.92%\nEpoch 76/100, Loss: 0.1238, Accuracy: 94.85%\nEpoch 77/100, Loss: 0.1217, Accuracy: 94.92%\nEpoch 78/100, Loss: 0.1201, Accuracy: 94.93%\nEpoch 79/100, Loss: 0.1210, Accuracy: 94.94%\nEpoch 80/100, Loss: 0.1206, Accuracy: 94.94%\nEpoch 81/100, Loss: 0.1203, Accuracy: 94.93%\nEpoch 82/100, Loss: 0.1236, Accuracy: 94.84%\nEpoch 83/100, Loss: 0.1201, Accuracy: 94.94%\nEpoch 84/100, Loss: 0.1236, Accuracy: 94.88%\nEpoch 85/100, Loss: 0.1190, Accuracy: 94.96%\nEpoch 86/100, Loss: 0.1213, Accuracy: 94.94%\nEpoch 87/100, Loss: 0.1214, Accuracy: 94.93%\nEpoch 88/100, Loss: 0.1211, Accuracy: 94.92%\nEpoch 89/100, Loss: 0.1195, Accuracy: 94.97%\nEpoch 90/100, Loss: 0.1221, Accuracy: 94.88%\nEpoch 91/100, Loss: 0.1214, Accuracy: 94.90%\nEpoch 92/100, Loss: 0.1218, Accuracy: 94.90%\nEpoch 93/100, Loss: 0.1197, Accuracy: 94.96%\nEpoch 94/100, Loss: 0.1208, Accuracy: 94.93%\nEpoch 95/100, Loss: 0.1205, Accuracy: 94.93%\nEpoch 96/100, Loss: 0.1215, Accuracy: 94.91%\nEpoch 97/100, Loss: 0.1221, Accuracy: 94.91%\nEpoch 98/100, Loss: 0.1194, Accuracy: 94.97%\nEpoch 99/100, Loss: 0.1208, Accuracy: 94.93%\nEpoch 100/100, Loss: 0.1214, Accuracy: 94.92%\nEpoch 101/100, Loss: 0.1189, Accuracy: 95.00%\nEpoch 102/100, Loss: 0.1211, Accuracy: 94.92%\nEpoch 103/100, Loss: 0.1207, Accuracy: 94.92%\nEpoch 104/100, Loss: 0.1224, Accuracy: 94.86%\nEpoch 105/100, Loss: 0.1207, Accuracy: 94.91%\nEpoch 106/100, Loss: 0.1198, Accuracy: 94.98%\nEpoch 107/100, Loss: 0.1204, Accuracy: 94.94%\nEpoch 108/100, Loss: 0.1215, Accuracy: 94.91%\nEpoch 109/100, Loss: 0.1198, Accuracy: 94.95%\nEpoch 110/100, Loss: 0.1205, Accuracy: 94.93%\nEpoch 111/100, Loss: 0.1207, Accuracy: 94.92%\nEpoch 112/100, Loss: 0.1208, Accuracy: 94.92%\nEpoch 113/100, Loss: 0.1187, Accuracy: 94.99%\nEpoch 114/100, Loss: 0.1202, Accuracy: 94.93%\nEpoch 115/100, Loss: 0.1190, Accuracy: 94.98%\nEpoch 116/100, Loss: 0.1203, Accuracy: 94.95%\nEpoch 117/100, Loss: 0.1179, Accuracy: 95.01%\nEpoch 118/100, Loss: 0.1203, Accuracy: 94.95%\nEpoch 119/100, Loss: 0.1206, Accuracy: 94.91%\nEpoch 120/100, Loss: 0.1185, Accuracy: 94.98%\nEpoch 121/100, Loss: 0.1208, Accuracy: 94.91%\nEpoch 122/100, Loss: 0.1211, Accuracy: 94.94%\nEpoch 123/100, Loss: 0.1200, Accuracy: 94.93%\nEpoch 124/100, Loss: 0.1200, Accuracy: 94.94%\nEpoch 125/100, Loss: 0.1184, Accuracy: 95.00%\nEpoch 126/100, Loss: 0.1171, Accuracy: 95.03%\nEpoch 127/100, Loss: 0.1203, Accuracy: 94.94%\nEpoch 128/100, Loss: 0.1200, Accuracy: 94.94%\nEpoch 129/100, Loss: 0.1192, Accuracy: 94.97%\nEpoch 130/100, Loss: 0.1195, Accuracy: 94.95%\nEpoch 131/100, Loss: 0.1198, Accuracy: 94.96%\nEpoch 132/100, Loss: 0.1199, Accuracy: 94.92%\nEpoch 133/100, Loss: 0.1193, Accuracy: 94.98%\nEpoch 134/100, Loss: 0.1205, Accuracy: 94.92%\nEpoch 135/100, Loss: 0.1203, Accuracy: 94.92%\nEpoch 136/100, Loss: 0.1176, Accuracy: 95.01%\nEpoch 137/100, Loss: 0.1197, Accuracy: 94.95%\nEpoch 138/100, Loss: 0.1176, Accuracy: 94.99%\nEpoch 139/100, Loss: 0.1191, Accuracy: 94.95%\nEpoch 140/100, Loss: 0.1200, Accuracy: 94.95%\nEpoch 141/100, Loss: 0.1181, Accuracy: 95.01%\nEpoch 142/100, Loss: 0.1199, Accuracy: 94.95%\nEpoch 143/100, Loss: 0.1180, Accuracy: 95.00%\nEpoch 144/100, Loss: 0.1187, Accuracy: 94.99%\nEpoch 145/100, Loss: 0.1203, Accuracy: 94.93%\nEpoch 146/100, Loss: 0.1186, Accuracy: 94.99%\nEpoch 147/100, Loss: 0.1198, Accuracy: 94.94%\nEpoch 148/100, Loss: 0.1195, Accuracy: 94.95%\nEpoch 149/100, Loss: 0.1206, Accuracy: 94.93%\nEpoch 150/100, Loss: 0.1179, Accuracy: 94.97%\nEpoch 151/100, Loss: 0.1182, Accuracy: 94.98%\nEpoch 152/100, Loss: 0.1222, Accuracy: 94.88%\nEpoch 153/100, Loss: 0.1173, Accuracy: 95.00%\nEpoch 154/100, Loss: 0.1175, Accuracy: 95.02%\nEpoch 155/100, Loss: 0.1186, Accuracy: 94.98%\nEpoch 156/100, Loss: 0.1196, Accuracy: 94.94%\nEpoch 157/100, Loss: 0.1180, Accuracy: 95.00%\nEpoch 158/100, Loss: 0.1183, Accuracy: 94.97%\nEpoch 159/100, Loss: 0.1188, Accuracy: 94.96%\nEpoch 160/100, Loss: 0.1183, Accuracy: 95.01%\nEpoch 161/100, Loss: 0.1189, Accuracy: 94.95%\nEpoch 162/100, Loss: 0.1180, Accuracy: 95.00%\nEpoch 163/100, Loss: 0.1207, Accuracy: 94.94%\nEpoch 164/100, Loss: 0.1184, Accuracy: 94.98%\nEpoch 165/100, Loss: 0.1184, Accuracy: 94.96%\nEpoch 166/100, Loss: 0.1183, Accuracy: 94.97%\nEpoch 167/100, Loss: 0.1173, Accuracy: 95.00%\nEpoch 168/100, Loss: 0.1179, Accuracy: 94.97%\nEpoch 169/100, Loss: 0.1177, Accuracy: 94.98%\nEpoch 170/100, Loss: 0.1173, Accuracy: 95.03%\nEpoch 171/100, Loss: 0.1183, Accuracy: 94.99%\nEpoch 172/100, Loss: 0.1183, Accuracy: 94.99%\nEpoch 173/100, Loss: 0.1192, Accuracy: 94.96%\nEpoch 174/100, Loss: 0.1185, Accuracy: 94.96%\nEpoch 175/100, Loss: 0.1174, Accuracy: 95.01%\nEpoch 176/100, Loss: 0.1175, Accuracy: 95.00%\nEpoch 177/100, Loss: 0.1183, Accuracy: 94.98%\nEpoch 178/100, Loss: 0.1188, Accuracy: 94.98%\nEpoch 179/100, Loss: 0.1175, Accuracy: 95.00%\nEpoch 180/100, Loss: 0.1175, Accuracy: 95.01%\nEpoch 181/100, Loss: 0.1186, Accuracy: 94.96%\nEpoch 182/100, Loss: 0.1167, Accuracy: 95.02%\nEpoch 183/100, Loss: 0.1175, Accuracy: 95.00%\nEpoch 184/100, Loss: 0.1179, Accuracy: 94.97%\nEpoch 185/100, Loss: 0.1189, Accuracy: 94.96%\nEpoch 186/100, Loss: 0.1177, Accuracy: 95.01%\nEpoch 187/100, Loss: 0.1169, Accuracy: 95.02%\nEpoch 188/100, Loss: 0.1170, Accuracy: 95.02%\nEpoch 189/100, Loss: 0.1166, Accuracy: 95.03%\nEpoch 190/100, Loss: 0.1202, Accuracy: 94.93%\nEpoch 191/100, Loss: 0.1175, Accuracy: 95.01%\nEpoch 192/100, Loss: 0.1175, Accuracy: 94.99%\nEpoch 193/100, Loss: 0.1169, Accuracy: 94.99%\nEpoch 194/100, Loss: 0.1309, Accuracy: 94.63%\nEpoch 195/100, Loss: 0.1144, Accuracy: 95.07%\nEpoch 196/100, Loss: 0.1147, Accuracy: 95.06%\nEpoch 197/100, Loss: 0.1158, Accuracy: 95.06%\nEpoch 198/100, Loss: 0.1138, Accuracy: 95.09%\nEpoch 199/100, Loss: 0.1164, Accuracy: 95.02%\nEpoch 200/100, Loss: 0.1174, Accuracy: 94.99%\nTest Accuracy: 94.58%\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"# save model \ntorch.save(model.state_dict(), '/kaggle/working/model_tetris_cnn8.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T15:56:03.390188Z","iopub.execute_input":"2025-01-02T15:56:03.390532Z","iopub.status.idle":"2025-01-02T15:56:03.398696Z","shell.execute_reply.started":"2025-01-02T15:56:03.390502Z","shell.execute_reply":"2025-01-02T15:56:03.397821Z"}},"outputs":[],"execution_count":35}]}